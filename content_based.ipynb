{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Content Based Recommender System"
      ],
      "metadata": {
        "id": "7vSifZsglp-f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook builds and implements a content based recommender system using Pyspark. This system focuses on three key book features; popular_shelves, genre and title. Term Frequency-Inverse Document Frequency (TF-IDF) is utilised to convert the set of strings for each book into numerical values. Term frequency measures the frequency of a word in a document. Inverse document frequency is a measure of how common or rare a word is across the entire dataset. When combined TF-IDF increases proportionally to the occurances of a word in a document, but is offset by the number of documnets that contain that word. TF-IDF can be used to compute a score that is indicative of the importance of each word within the document and the corpus.\n",
        "\n",
        "Below we build a ML Pipeline (a set of high-level APIs built on top of DataFrames) that applies TF-IDF vectorization to all strings passed. This transforms the strings to numerical data so we can compare books and calculate their similarity using a similarity score (cosine similarity).\n",
        " \n",
        "Overview:\n",
        "\n",
        "*   Imports\n",
        "*   Data Loading\n",
        "*   Text Processing and Featurization\n",
        "*   Recommendations based on book list\n",
        "*   Recommendations for users\n",
        "*   Evaluation"
      ],
      "metadata": {
        "id": "IrUr_coeJHKF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import packages and libraries"
      ],
      "metadata": {
        "id": "6gUBfpD6lpwj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uG3SQ7cjvGPw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from ast import literal_eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kuoGT70UkKNe"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.0.3/spark-3.0.3-bin-hadoop2.7.tgz\n",
        "!tar -xvf spark-3.0.3-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BDkBmwhok_xV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.3-bin-hadoop2.7\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "M5DatdnAlEal"
      },
      "outputs": [],
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "import pyspark # only run after findspark.init()\n",
        "\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.sql import Row, SQLContext\n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "from pyspark.ml.feature import RegexTokenizer, CountVectorizer\n",
        "from pyspark.ml.feature import StopWordsRemover, VectorAssembler\n",
        "from pyspark.ml.feature import Word2Vec, Word2VecModel\n",
        "from pyspark.ml.feature import IDF\n",
        "from pyspark.ml import Pipeline, PipelineModel\n",
        "\n",
        "# Create new config\n",
        "conf = SparkConf().set(\"spark.driver.maxResultSize\", \"20g\")\n",
        "\n",
        "sc = SparkContext(appName=\"PythonKMeans\", sparkHome=\"/content/spark-3.0.3-bin-hadoop2.7\", conf=conf)    \n",
        "sqlContext = SQLContext(sc)\n",
        "\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgR6Lf5XmFOu",
        "outputId": "f7238efe-885c-47e5-e502-d7992105b2f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnAEOlWM9iJ0"
      },
      "source": [
        "## Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9-283KY6VCD",
        "outputId": "d3bb95d8-b0be-45df-a89f-c9d9e0bf15e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- isbn: string (nullable = true)\n",
            " |-- text_reviews_count: integer (nullable = true)\n",
            " |-- series: string (nullable = true)\n",
            " |-- country_code: string (nullable = true)\n",
            " |-- language_code: string (nullable = true)\n",
            " |-- popular_shelves: string (nullable = true)\n",
            " |-- asin: string (nullable = true)\n",
            " |-- is_ebook: boolean (nullable = true)\n",
            " |-- average_rating: double (nullable = true)\n",
            " |-- kindle_asin: string (nullable = true)\n",
            " |-- similar_books: string (nullable = true)\n",
            " |-- description: string (nullable = true)\n",
            " |-- format: string (nullable = true)\n",
            " |-- link: string (nullable = true)\n",
            " |-- authors: string (nullable = true)\n",
            " |-- publisher: string (nullable = true)\n",
            " |-- num_pages: double (nullable = true)\n",
            " |-- publication_day: double (nullable = true)\n",
            " |-- isbn13: double (nullable = true)\n",
            " |-- publication_month: double (nullable = true)\n",
            " |-- edition_information: string (nullable = true)\n",
            " |-- publication_year: double (nullable = true)\n",
            " |-- url: string (nullable = true)\n",
            " |-- image_url: string (nullable = true)\n",
            " |-- book_id: integer (nullable = true)\n",
            " |-- ratings_count: integer (nullable = true)\n",
            " |-- work_id: integer (nullable = true)\n",
            " |-- title: string (nullable = true)\n",
            " |-- title_without_series: string (nullable = true)\n",
            " |-- genre: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "books_df = spark.read.option(\"inferSchema\",True) \\\n",
        "                .option(\"delimiter\",\"|\") \\\n",
        "                .option(\"header\",True) \\\n",
        "  .csv(\"drive/MyDrive/ca4022_data/books_delimeter_fixed.csv\")\n",
        "books_df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65OYBcuMKymB",
        "outputId": "317d12f3-670f-4a75-9262-ea9731514975"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------------+--------------------+------------+-------------+--------------------+----+--------+--------------+-----------+--------------------+--------------------+---------+--------------------+--------------------+----------------+---------+---------------+----------+-----------------+-------------------+----------------+--------------------+--------------------+-------+-------------+-------+--------------------+--------------------+--------+\n",
            "|     isbn|text_reviews_count|              series|country_code|language_code|     popular_shelves|asin|is_ebook|average_rating|kindle_asin|       similar_books|         description|   format|                link|             authors|       publisher|num_pages|publication_day|    isbn13|publication_month|edition_information|publication_year|                 url|           image_url|book_id|ratings_count|work_id|               title|title_without_series|   genre|\n",
            "+---------+------------------+--------------------+------------+-------------+--------------------+----+--------+--------------+-----------+--------------------+--------------------+---------+--------------------+--------------------+----------------+---------+---------------+----------+-----------------+-------------------+----------------+--------------------+--------------------+-------+-------------+-------+--------------------+--------------------+--------+\n",
            "|590417010|               193|                  []|          US|          eng|[{'count': '450',...|null|   false|          4.43| B017RORXNI|['834493', '45218...|In Newbery Medali...|Hardcover|https://www.goodr...|[{'author_id': '5...|  Blue Sky Press|     40.0|            1.0|9.78059E12|              9.0|               null|          1995.0|https://www.goodr...|https://images.gr...|  89378|         1331|  86259|          Dog Heaven|          Dog Heaven|Children|\n",
            "|698114272|                65|                  []|          US|         null|[{'count': '90', ...|null|   false|          3.95|       null|['886410', '19743...|\"Seeing bully Boo...|Paperback|https://www.goodr...|[{'author_id': '2...|    Puffin Books|     32.0|           19.0| 9.7807E12|              5.0|               null|          1997.0|https://www.goodr...|https://s.gr-asse...|  38565|          299|  38327|Bootsie Barker Bites|Bootsie Barker Bites|Children|\n",
            "|763615765|               181|                  []|          US|        en-US|[{'count': '1110'...|null|   false|          4.08|       null|['773278', '88048...|As he sets about ...|     null|https://www.goodr...|[{'author_id': '1...|Candlewick Press|     null|           12.0|9.78076E12|             11.0|               null|          2001.0|https://www.goodr...|https://s.gr-asse...| 821430|         4505| 885037|                 Hug|                 Hug|Children|\n",
            "|142407437|               140|                  []|          US|         null|[{'count': '267',...|null|   false|          4.39|       null|['3820177', '1801...|                null|Paperback|https://www.goodr...|[{'author_id': '1...|    Puffin Books|     32.0|           15.0|9.78014E12|              2.0|               null|          2007.0|https://www.goodr...|https://s.gr-asse...| 248169|          624| 240460|Our Tree Named Steve|Our Tree Named Steve|Children|\n",
            "|590503111|               105|['145899', '674116']|          US|          eng|[{'count': '407',...|null|   false|           4.1| B00JSXU42Y|['834688', '64490...|This is a wacky s...|     null|https://www.goodr...|[{'author_id': '1...|            null|     null|           null|9.78059E12|             null|               null|            null|https://www.goodr...|https://s.gr-asse...| 111002|         1378| 106925|The Librarian fro...|The Librarian fro...|Children|\n",
            "+---------+------------------+--------------------+------------+-------------+--------------------+----+--------+--------------+-----------+--------------------+--------------------+---------+--------------------+--------------------+----------------+---------+---------------+----------+-----------------+-------------------+----------------+--------------------+--------------------+-------+-------------+-------+--------------------+--------------------+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "books_df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GHztbn72fod",
        "outputId": "df255313-0cba-4448-f5a9-0eeef9625343"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- user_id: integer (nullable = true)\n",
            " |-- book_id: integer (nullable = true)\n",
            " |-- is_read: integer (nullable = true)\n",
            " |-- rating: integer (nullable = true)\n",
            " |-- is_reviewed: double (nullable = true)\n",
            " |-- user_count: integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "interactions_df = spark.read.option(\"inferSchema\",True) \\\n",
        "                .option(\"delimiter\",\",\") \\\n",
        "                .option(\"header\",True) \\\n",
        "  .csv(\"drive/MyDrive/ca4022_data/new_interactions.csv\")\n",
        "interactions_df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOLQZAae2nub",
        "outputId": "8e1e0b4a-ae95-468d-d112-03c67b616178"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+-------+------+-----------+----------+\n",
            "|user_id|book_id|is_read|rating|is_reviewed|user_count|\n",
            "+-------+-------+-------+------+-----------+----------+\n",
            "|      0|    915|      1|     5|        1.0|        15|\n",
            "|      0|    873|      1|     4|        0.0|        15|\n",
            "|      0|    871|      1|     2|        0.0|        15|\n",
            "|      0|    870|      1|     3|        0.0|        15|\n",
            "|      0|    824|      1|     5|        1.0|        15|\n",
            "+-------+-------+-------+------+-----------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "interactions_df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "EQiz3vJUPoeH"
      },
      "outputs": [],
      "source": [
        "# create SQL view for later queries\n",
        "interactions_df.createOrReplaceTempView(\"interactions\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmoD1zLJul29"
      },
      "source": [
        "## Text Processing and Featurization"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prepare the data**"
      ],
      "metadata": {
        "id": "2QZxZCpUPH_G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "XuGCH2IRkQfW"
      },
      "outputs": [],
      "source": [
        "stop_words = set(['reading', 'read', 'currently', 'find', 'awaiting', 'on', 'books', 'book', 'owned', 'own', 'library', 'to', 'bookshelf', 'shelf', 'i', 'my', 'did', 'not', 'didn', 't',  'finish', 'finished', 'and', 'favorites', 'favorite', 's', 'recommend'])\n",
        "def shelves_to_string(shelves_dict):\n",
        "  shelves_list = literal_eval(shelves_dict)\n",
        "  string_of_shelves = 'nothing '\n",
        "  for shelf_dict in shelves_list:\n",
        "    cnt = shelf_dict['count']\n",
        "    shelf = shelf_dict['name']\n",
        "    if shelf == 'non-fiction ':\n",
        "      shelf = ''.join(shelf.split('-'))\n",
        "    print(set(shelf.split('-')))\n",
        "    to_add = set(shelf.split('-')).difference(stop_words)\n",
        "    string_of_shelves += ' '.join(int(cnt) * list(to_add)) + ' '\n",
        "  return string_of_shelves"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Popular_shelves are stored in a list of dictionaries of the form: [{'count': c},{'name': n}].\n",
        "The above function takes a list of dictionaries for a single book and produces a string of the shelf names combined. We muliply each shelf's name by its count as it is important to capture the popularity of each shelf as we will soon perform TF-IDF on the string. We also remove 'stop_words' (terms) that we deem uninformative."
      ],
      "metadata": {
        "id": "cFcu_y_8M5Ql"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DataFrame with book_id and string to be vectorized**"
      ],
      "metadata": {
        "id": "EJ3Cnivc_HhK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6KA1O_rKeVlL"
      },
      "outputs": [],
      "source": [
        "shelves_df = spark.createDataFrame(books_df.rdd.map(lambda x: x.genre + ' ' + x.title + ' ' + shelves_to_string(x.popular_shelves)),StringType(),['shelves'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKdhVwWpjqy8",
        "outputId": "4c669637-fd06-4f98-a88e-72cd820246df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(value='Children Dog Heaven nothing  picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture animals animals animals animals animals animals animals animals animals animals animals animals animals animals animals animals animals animals animals animals animals animals animals animals animals animals children children children children children children children children children children children children children children children children children children children children children children childrens childrens childrens childrens childrens childrens childrens childrens childrens childrens childrens childrens childrens childrens childrens childrens childrens childrens childrens childrens childrens dogs dogs dogs dogs dogs dogs dogs dogs dogs dogs dogs dogs dogs dogs dogs dogs dogs dogs dogs dogs death death death death death death death death death death death death death death death death death death children children children children children children children children children children children children children children children children children picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture picture children children children children children children children children children children children children  kids kids kids kids kids kids kids kids kids kids  pets pets pets pets pets pets pets pets lit children lit children lit children lit children lit children lit children lit children lit children fiction fiction fiction fiction fiction fiction fiction fiction childrens childrens childrens childrens childrens childrens childrens childrens heaven heaven heaven heaven heaven heaven heaven dog dog dog dog dog dog dog children literature children literature children literature children literature children literature children literature rylant cynthia rylant cynthia rylant cynthia rylant cynthia rylant cynthia grief grief grief grief grief default default default default  kids kids kids bibliotherapy bibliotherapy bibliotherapy religion religion religion inclusion diversity inclusion diversity inclusion diversity lit childrens lit childrens lit childrens  death grief death grief picture story picture story children picture children picture kiddos kiddos spirituality spirituality of a pet loss of a pet loss childhood childhood school counseling school counseling classroom classroom self help self help young children young children events unfortunate events unfortunate helpful helpful appreciation appreciation acceptance acceptance ece 3601 ece 3601 class class closet closet 813 5 813 5 classroom classroom tales dog tales dog christian christian angels angels non fiction non fiction illustrated illustrated children children god god animal animal picture picture kid kid children picture children picture childrens childrens 2017 year l at fiction h a2 a kids teen zone 2 writing teach child fiction premiere wishlist picturebooks  mg picture ya fiction kids for mental resources health littles kids fiction family kids early elem dogs animals death dying grief childrens_picture childrens fiction stuff scary about secular best judaica resources rylant cynthia author study animals picture tales animal at 5 alex 6 age slastic_50_1gr literature afterlife 1000bb4k kids gr1 kids 2 c l mortality 1 summer izzy 000 k 2 ')]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "shelves_df.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "wmv_ehlde7Bz"
      },
      "outputs": [],
      "source": [
        "DF1 = books_df.withColumn(\"row_id\", monotonically_increasing_id())\n",
        "DF2 = shelves_df.withColumn(\"row_id\", monotonically_increasing_id())\n",
        "books_expanded_df = DF1.join(DF2, (\"row_id\")).drop(\"row_id\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "8Ne0x3jQ9hH5"
      },
      "outputs": [],
      "source": [
        "# create SQL view for later queries\n",
        "books_expanded_df.createOrReplaceTempView(\"books\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXRYxx9f_yND",
        "outputId": "ebe97c48-de3b-4a9a-e788-8ee5436e2647"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+\n",
            "|book_id|               value|\n",
            "+-------+--------------------+\n",
            "|  89378|Children Dog Heav...|\n",
            "|  38565|Children Bootsie ...|\n",
            "| 821430|Children Hug noth...|\n",
            "+-------+--------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "book_shelves = spark.sql(\"SELECT book_id, value FROM books\")\n",
        "book_shelves.show(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have the strings prepared for the next stage: model building."
      ],
      "metadata": {
        "id": "uE6mmYzNOp0W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create the pipeline, fit the model and transform the data**"
      ],
      "metadata": {
        "id": "HPfBWbf-PF0j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the necessary processing pipeline is a resouce-intensive process. To save on computational time we will only create the pipeline once and then save the model. The pipeline can then be loading in, in all future runs."
      ],
      "metadata": {
        "id": "ccX0mugIFzcS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "SF6LkXXmuvZR"
      },
      "outputs": [],
      "source": [
        "# create text processing pipeline -- this a lengthy resouce-intensive process (we only need to do it once)\n",
        "\n",
        "# # Build the pipeline \n",
        "# regexTokenizer = RegexTokenizer(gaps = False, pattern = '\\w+', inputCol = 'value', outputCol = 'token')\n",
        "# stopWordsRemover = StopWordsRemover(inputCol = 'token', outputCol = 'nostopwrd')\n",
        "# countVectorizer = CountVectorizer(inputCol=\"nostopwrd\", outputCol=\"rawFeature\")\n",
        "# iDF = IDF(inputCol=\"rawFeature\", outputCol=\"idf_vec\")\n",
        "# word2Vec = Word2Vec(vectorSize = 100, minCount = 5, inputCol = 'nostopwrd', outputCol = 'word_vec', seed=123)\n",
        "# vectorAssembler = VectorAssembler(inputCols=['idf_vec', 'word_vec'], outputCol='comb_vec')\n",
        "# pipeline = Pipeline(stages=[regexTokenizer, stopWordsRemover, countVectorizer, iDF, word2Vec, vectorAssembler])\n",
        "\n",
        "# # fit the model\n",
        "# pipeline_mdl = pipeline.fit(book_shelves)\n",
        "\n",
        "# #save the pipeline model\n",
        "# pipeline_mdl.write().overwrite().save('drive/MyDrive/content_model/' + 'pipe_txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "7Ynv_7bUuvcS"
      },
      "outputs": [],
      "source": [
        "# load the text transformation pipeline trained model\n",
        "\n",
        "pipeline_mdl = PipelineModel.load('drive/MyDrive/content_model/pipe_txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "8VBxMVa3v7qh"
      },
      "outputs": [],
      "source": [
        "# transform the data\n",
        "\n",
        "book_shelves_trf_df = pipeline_mdl.transform(book_shelves)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blRRd4bCv7uD",
        "outputId": "3a079792-c6ac-496c-ea89-119e7076b451"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|               value|           nostopwrd|             idf_vec|            word_vec|            comb_vec|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|Children Dog Heav...|[children, dog, h...|(49019,[1,4,5,6,8...|[0.15958723609852...|(49119,[1,4,5,6,8...|\n",
            "|Children Bootsie ...|[children, bootsi...|(49019,[0,1,5,6,1...|[0.15040656500409...|(49119,[0,1,5,6,1...|\n",
            "|Children Hug noth...|[children, hug, n...|(49019,[1,5,6,8,1...|[0.15815774049439...|(49119,[1,5,6,8,1...|\n",
            "|Children Our Tree...|[children, tree, ...|(49019,[1,3,5,6,8...|[0.15787570753524...|(49119,[1,3,5,6,8...|\n",
            "|Children The Libr...|[children, librar...|(49019,[0,1,5,6,1...|[0.10311328777520...|(49119,[0,1,5,6,1...|\n",
            "|Children The Libr...|[children, librar...|(49019,[1,3,4,5,6...|[0.22209633309716...|(49119,[1,3,4,5,6...|\n",
            "|Children Nightmar...|[children, nightm...|(49019,[1,3,4,5,6...|[-0.0086990651621...|(49119,[1,3,4,5,6...|\n",
            "|Children The Pink...|[children, pink, ...|(49019,[0,5,6,17,...|[0.12985617477439...|(49119,[0,5,6,17,...|\n",
            "|Children Encyclop...|[children, encycl...|(49019,[1,3,4,5,6...|[0.12510652285212...|(49119,[1,3,4,5,6...|\n",
            "|Children Stronger...|[children, strong...|(49019,[0,1,3,4,5...|[0.04510302573384...|(49119,[0,1,3,4,5...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# show the transformed data\n",
        "\n",
        "book_shelves_trf_df.select( 'value', 'nostopwrd', 'idf_vec', 'word_vec', 'comb_vec').show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "auC4IV_Iv7xt"
      },
      "outputs": [],
      "source": [
        "all_books_vecs = book_shelves_trf_df.select('book_id', 'word_vec').rdd.map(lambda x: (x[0], x[1])).collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQaM9vdVv71W",
        "outputId": "6bdcfeba-1acf-40f2-d1d6-85fdd53e654c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(38565,\n",
              " DenseVector([0.1504, 0.0364, 0.0404, 0.0191, 0.0294, -0.0917, -0.138, 0.0872, 0.0097, 0.0633, 0.1165, 0.3216, 0.0251, 0.0311, 0.1541, 0.1191, -0.1177, -0.113, -0.0326, 0.2084, -0.1283, 0.1932, 0.0088, 0.1231, 0.1393, -0.0231, -0.0865, -0.0287, 0.1111, -0.0551, -0.0094, 0.092, 0.0835, 0.0421, 0.0066, -0.0133, 0.0281, -0.0514, 0.0228, -0.1691, 0.1419, 0.0556, -0.206, -0.0195, 0.0221, -0.1686, -0.2071, -0.0801, 0.2746, 0.075, 0.0156, -0.1161, -0.0239, 0.1799, -0.0831, -0.3074, -0.0577, 0.1436, -0.1707, -0.1385, 0.1471, 0.1858, -0.0246, -0.3295, -0.1627, 0.2134, 0.1844, 0.0038, -0.1225, -0.0963, -0.0857, 0.2226, -0.1052, 0.1876, 0.2017, 0.1356, -0.0656, 0.0589, -0.1337, -0.0966, -0.0294, -0.1284, 0.0884, -0.0023, 0.1276, -0.128, 0.0869, 0.1858, 0.2188, -0.1719, 0.0514, -0.0187, 0.0187, -0.1296, -0.1485, -0.0248, -0.0526, 0.2668, -0.2566, -0.281]))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# peek at one row\n",
        "\n",
        "all_books_vecs[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Similar Books"
      ],
      "metadata": {
        "id": "VlO26NKZjo-a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define a similarity measure**  \n",
        "We will use cosine similarity to assess the similarity of any two books."
      ],
      "metadata": {
        "id": "H2GCb9RpO5_m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "xicC6Ej0wSvU"
      },
      "outputs": [],
      "source": [
        "def CosineSim(vec1, vec2): \n",
        "    return np.dot(vec1, vec2) / np.sqrt(np.dot(vec1, vec1)) / np.sqrt(np.dot(vec2, vec2)) "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function to display book information**"
      ],
      "metadata": {
        "id": "dkvNdSc4PiWc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "MsLV181hDOWL"
      },
      "outputs": [],
      "source": [
        "def getBookDetails(in_book):\n",
        "    \n",
        "    a = in_book.alias(\"a\")\n",
        "    b = books_df.alias(\"b\")\n",
        "    \n",
        "    return a.join(b, col(\"a.book_id\") == col(\"b.book_id\"), 'inner').select([col('a.'+xx) for xx in a.columns] + [col('b.title'), col('b.publication_year'), col('b.genre')])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function to get similar books**  \n",
        "This function will take a list of books as input and output the top 10 most similar books to those inputted books."
      ],
      "metadata": {
        "id": "Pg_mPzOSPnEw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "eEwTsG030ukE"
      },
      "outputs": [],
      "source": [
        "def getSimilarBooks(b_ids, sim_books_limit=10):\n",
        "    \n",
        "    schema = StructType([   \n",
        "                            StructField(\"book_id\", IntegerType(), True)\n",
        "                            ,StructField(\"score\", IntegerType(), True)\n",
        "                            ,StructField(\"input_book_id\", IntegerType(), True)\n",
        "                        ])\n",
        "    \n",
        "    similar_books_df = spark.createDataFrame([], schema)\n",
        "    \n",
        "    for b_id in b_ids:\n",
        "        \n",
        "        input_vec = [(r[1]) for r in all_books_vecs if r[0] == b_id][0]\n",
        "\n",
        "        similar_book_rdd = sc.parallelize((i[0], float(CosineSim(input_vec, i[1]))) for i in all_books_vecs)\n",
        "\n",
        "        similar_book_df = spark.createDataFrame(similar_book_rdd) \\\n",
        "            .withColumnRenamed('_1', 'book_id') \\\n",
        "            .withColumnRenamed('_2', 'score') \\\n",
        "            .orderBy(\"score\", ascending = False)\n",
        "\n",
        "            \n",
        "        similar_book_df = similar_book_df.filter(col(\"book_id\") != b_id).dropDuplicates(['book_id']).orderBy(\"score\", ascending = False).limit(sim_books_limit)\n",
        "\n",
        "        similar_book_df = similar_book_df.withColumn('input_book_id', lit(b_id))\n",
        "\n",
        "        similar_books_df = similar_books_df \\\n",
        "                                    .union(similar_book_df)\n",
        "        \n",
        "    \n",
        "    return similar_books_df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 1**"
      ],
      "metadata": {
        "id": "23jtTSOuPzqN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "CdDP8NxGDOYr",
        "outputId": "57811551-00ed-47f5-813c-c36baea7aaf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------------------------------------------------+----------------+--------+\n",
            "|book_id|title                                              |publication_year|genre   |\n",
            "+-------+---------------------------------------------------+----------------+--------+\n",
            "|412348 |Nightmare in Death Valley (Sweet Valley High, #116)|1995.0          |Children|\n",
            "+-------+---------------------------------------------------+----------------+--------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>book_id</th>\n",
              "      <th>score</th>\n",
              "      <th>input_book_id</th>\n",
              "      <th>title</th>\n",
              "      <th>publication_year</th>\n",
              "      <th>genre</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12771</td>\n",
              "      <td>0.993135</td>\n",
              "      <td>412348</td>\n",
              "      <td>A Kiss Before Dying (Sweet Valley High, #122)</td>\n",
              "      <td>1996.0</td>\n",
              "      <td>Young Adult</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12771</td>\n",
              "      <td>0.993135</td>\n",
              "      <td>412348</td>\n",
              "      <td>A Kiss Before Dying (Sweet Valley High, #122)</td>\n",
              "      <td>1996.0</td>\n",
              "      <td>Children</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>412190</td>\n",
              "      <td>0.993130</td>\n",
              "      <td>412348</td>\n",
              "      <td>The Pom-Pom Wars (Sweet Valley High, #113)</td>\n",
              "      <td>1995.0</td>\n",
              "      <td>Young Adult</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>412353</td>\n",
              "      <td>0.992544</td>\n",
              "      <td>412348</td>\n",
              "      <td>Elizabeth Betrayed (Sweet Valley High, #89)</td>\n",
              "      <td>1992.0</td>\n",
              "      <td>Young Adult</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>412353</td>\n",
              "      <td>0.992544</td>\n",
              "      <td>412348</td>\n",
              "      <td>Elizabeth Betrayed (Sweet Valley High, #89)</td>\n",
              "      <td>1992.0</td>\n",
              "      <td>Children</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>412262</td>\n",
              "      <td>0.992341</td>\n",
              "      <td>412348</td>\n",
              "      <td>A Date with a Werewolf (Sweet Valley High, #105)</td>\n",
              "      <td>1994.0</td>\n",
              "      <td>Young Adult</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>292386</td>\n",
              "      <td>0.991571</td>\n",
              "      <td>412348</td>\n",
              "      <td>\"\"\"V\"\" Is for Victory (Sweet Valley High, #114)\"</td>\n",
              "      <td>1995.0</td>\n",
              "      <td>Young Adult</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>292389</td>\n",
              "      <td>0.991285</td>\n",
              "      <td>412348</td>\n",
              "      <td>Almost Married (Sweet Valley High, #102)</td>\n",
              "      <td>1995.0</td>\n",
              "      <td>Young Adult</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>412359</td>\n",
              "      <td>0.990674</td>\n",
              "      <td>412348</td>\n",
              "      <td>Beware the Wolfman (Sweet Valley High, #106)</td>\n",
              "      <td>1994.0</td>\n",
              "      <td>Young Adult</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>412356</td>\n",
              "      <td>0.989994</td>\n",
              "      <td>412348</td>\n",
              "      <td>Enid's Story (Sweet Valley High, Super Star #3)</td>\n",
              "      <td>1990.0</td>\n",
              "      <td>Young Adult</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>412394</td>\n",
              "      <td>0.989390</td>\n",
              "      <td>412348</td>\n",
              "      <td>Kidnapped by the Cult! (Sweet Valley High, #82)</td>\n",
              "      <td>1992.0</td>\n",
              "      <td>Young Adult</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>412189</td>\n",
              "      <td>0.989100</td>\n",
              "      <td>412348</td>\n",
              "      <td>Boy Trouble (Sweet Valley High, #61)</td>\n",
              "      <td>1989.0</td>\n",
              "      <td>Young Adult</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    book_id     score  ...  publication_year        genre\n",
              "0     12771  0.993135  ...            1996.0  Young Adult\n",
              "1     12771  0.993135  ...            1996.0     Children\n",
              "2    412190  0.993130  ...            1995.0  Young Adult\n",
              "3    412353  0.992544  ...            1992.0  Young Adult\n",
              "4    412353  0.992544  ...            1992.0     Children\n",
              "5    412262  0.992341  ...            1994.0  Young Adult\n",
              "6    292386  0.991571  ...            1995.0  Young Adult\n",
              "7    292389  0.991285  ...            1995.0  Young Adult\n",
              "8    412359  0.990674  ...            1994.0  Young Adult\n",
              "9    412356  0.989994  ...            1990.0  Young Adult\n",
              "10   412394  0.989390  ...            1992.0  Young Adult\n",
              "11   412189  0.989100  ...            1989.0  Young Adult\n",
              "\n",
              "[12 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "books_df.select('book_id','title', 'publication_year', 'genre') \\\n",
        "    .filter(books_df.book_id.isin([412348]) == True).show(1, truncate=False)\n",
        "\n",
        "getBookDetails(getSimilarBooks([412348])).toPandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These seem to be reasonable recommendations. The books suggested are books from the same series (Sweet Valley High) and in descending order. The model has correctly identified that books nearer to the edition of the inputted book are more similar to the inputted book."
      ],
      "metadata": {
        "id": "EhKe2OEV_cme"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 2**"
      ],
      "metadata": {
        "id": "lHCj-QNRAQrQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "2eF-SQYoKr47",
        "outputId": "64886c4d-2894-4acd-c2d6-9c2820a495d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+----------------+-----------------+\n",
            "|book_id|title   |publication_year|genre            |\n",
            "+-------+--------+----------------+-----------------+\n",
            "|6882   |Papillon|2006.0          |History/Biography|\n",
            "+-------+--------+----------------+-----------------+\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>book_id</th>\n",
              "      <th>score</th>\n",
              "      <th>input_book_id</th>\n",
              "      <th>title</th>\n",
              "      <th>publication_year</th>\n",
              "      <th>genre</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6883</td>\n",
              "      <td>0.964291</td>\n",
              "      <td>6882</td>\n",
              "      <td>Banco: The Further Adventures of Papillon</td>\n",
              "      <td>1985.0</td>\n",
              "      <td>History/Biography</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7753</td>\n",
              "      <td>0.959523</td>\n",
              "      <td>6882</td>\n",
              "      <td>Fear and Loathing: The Strange and Terrible Sa...</td>\n",
              "      <td>2004.0</td>\n",
              "      <td>History/Biography</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>163258</td>\n",
              "      <td>0.954871</td>\n",
              "      <td>6882</td>\n",
              "      <td>Once in a House on Fire</td>\n",
              "      <td>2004.0</td>\n",
              "      <td>History/Biography</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>77344</td>\n",
              "      <td>0.952868</td>\n",
              "      <td>6882</td>\n",
              "      <td>Angela's Ashes</td>\n",
              "      <td>1996.0</td>\n",
              "      <td>History/Biography</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>856991</td>\n",
              "      <td>0.952868</td>\n",
              "      <td>6882</td>\n",
              "      <td>Angela's Ashes</td>\n",
              "      <td>1999.0</td>\n",
              "      <td>History/Biography</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>856990</td>\n",
              "      <td>0.952866</td>\n",
              "      <td>6882</td>\n",
              "      <td>Angela's Ashes: A Memoir of a Childhood</td>\n",
              "      <td>1997.0</td>\n",
              "      <td>History/Biography</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>344717</td>\n",
              "      <td>0.952399</td>\n",
              "      <td>6882</td>\n",
              "      <td>The Boy Who Fell Out of the Sky</td>\n",
              "      <td>NaN</td>\n",
              "      <td>History/Biography</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>166562</td>\n",
              "      <td>0.950635</td>\n",
              "      <td>6882</td>\n",
              "      <td>Between a Rock and a Hard Place</td>\n",
              "      <td>2005.0</td>\n",
              "      <td>History/Biography</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>386990</td>\n",
              "      <td>0.949432</td>\n",
              "      <td>6882</td>\n",
              "      <td>Burned Alive</td>\n",
              "      <td>2005.0</td>\n",
              "      <td>History/Biography</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>23202</td>\n",
              "      <td>0.949048</td>\n",
              "      <td>6882</td>\n",
              "      <td>The Last American Man</td>\n",
              "      <td>NaN</td>\n",
              "      <td>History/Biography</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   book_id     score  ...  publication_year              genre\n",
              "0     6883  0.964291  ...            1985.0  History/Biography\n",
              "1     7753  0.959523  ...            2004.0  History/Biography\n",
              "2   163258  0.954871  ...            2004.0  History/Biography\n",
              "3    77344  0.952868  ...            1996.0  History/Biography\n",
              "4   856991  0.952868  ...            1999.0  History/Biography\n",
              "5   856990  0.952866  ...            1997.0  History/Biography\n",
              "6   344717  0.952399  ...               NaN  History/Biography\n",
              "7   166562  0.950635  ...            2005.0  History/Biography\n",
              "8   386990  0.949432  ...            2005.0  History/Biography\n",
              "9    23202  0.949048  ...               NaN  History/Biography\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "books_df.select('book_id','title', 'publication_year', 'genre') \\\n",
        "    .filter(books_df.book_id.isin([6882]) == True).show(truncate=False)\n",
        "\n",
        "getBookDetails(getSimilarBooks([6882])).toPandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These also appear to be relevant recommendations. The number one recommended book (Banco: The Further Adventures of Papillon) is the sequel to the inputted book (Papillon). The remainder of the recommendations are all of the same genre (History/Biography)."
      ],
      "metadata": {
        "id": "Bvycv1iKAUfa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recommendations for users"
      ],
      "metadata": {
        "id": "iwdX3skjj4cW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function that takes a user_id as input and outputs recommendations for that user"
      ],
      "metadata": {
        "id": "EDZtMGe_RqKG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "wxsk4-43DOcT"
      },
      "outputs": [],
      "source": [
        "def getContentRecoms(u_id, sim_books_limit=10,display=True):\n",
        "    \n",
        "    # select books previously read and reviewed (3+) by the user\n",
        "    query = \"\"\"\n",
        "    SELECT book_id FROM(\n",
        "    SELECT distinct book_id, rating FROM interactions  \n",
        "    where is_read = 1 and rating >= 3\n",
        "    and user_id = \"{}\"\n",
        "    order by rating desc\n",
        "    limit 5) \n",
        "    \"\"\".format(u_id)\n",
        "\n",
        "    usr_rev_books = sqlContext.sql(query)\n",
        "    \n",
        "    # from these get sample of 10 books\n",
        "    # usr_rev_books = usr_rev_books.limit(10)\n",
        "\n",
        "    usr_rev_books_det = getBookDetails(usr_rev_books)\n",
        "    \n",
        "    if display == True:\n",
        "      # show the sample details\n",
        "      print('\\nBooks previously read and reviewed by user:')\n",
        "      usr_rev_books_det.select(['book_id', 'title', 'publication_year', 'genre']).show(truncate = False)\n",
        "\n",
        "    book_list = [i.book_id for i in usr_rev_books.collect()]\n",
        "\n",
        "    # get books similar to the sample\n",
        "    sim_books_df = getSimilarBooks(book_list, sim_books_limit)\n",
        "\n",
        "    # filter out those have been reviewd before by the user\n",
        "    s = sim_books_df.alias(\"s\")\n",
        "    r = usr_rev_books.alias(\"r\")\n",
        "    j = s.join(r, col(\"s.book_id\") == col(\"r.book_id\"), 'left_outer') \\\n",
        "         .where(col(\"r.book_id\").isNull()) \\\n",
        "         .select([col('s.book_id'),col('s.score')])\n",
        "\n",
        "    a = j.orderBy(\"score\", ascending = False).limit(sim_books_limit)\n",
        "\n",
        "    return getBookDetails(a).orderBy(\"score\", ascending = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 1**"
      ],
      "metadata": {
        "id": "ef6a9nt_RsqQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "EN_bQi74MHrO",
        "outputId": "8f5036a3-79b2-48e3-cff4-878ad0528cea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Books previously read and reviewed by user:\n",
            "+-------+-----------------------------------------------------+----------------+-----------------+\n",
            "|book_id|title                                                |publication_year|genre            |\n",
            "+-------+-----------------------------------------------------+----------------+-----------------+\n",
            "|13119  |The Dark Side Of Genius: The Life Of Alfred Hitchcock|1999.0          |History/Biography|\n",
            "|13231  |Lewis Carroll: A Biography                           |1996.0          |History/Biography|\n",
            "|13140  |Jack & Jill (Alex Cross, #3)                         |2003.0          |Mystery          |\n",
            "|13215  |Life Doesn't Frighten Me                             |1996.0          |Poetry           |\n",
            "|13223  |The Complete Poems                                   |1996.0          |Poetry           |\n",
            "+-------+-----------------------------------------------------+----------------+-----------------+\n",
            "\n",
            "Books recommended to user based on previously read and reviewed books:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>book_id</th>\n",
              "      <th>score</th>\n",
              "      <th>title</th>\n",
              "      <th>publication_year</th>\n",
              "      <th>genre</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21436</td>\n",
              "      <td>0.999662</td>\n",
              "      <td>Cat and Mouse (Alex Cross, #4)</td>\n",
              "      <td>2007.0</td>\n",
              "      <td>Mystery</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>79378</td>\n",
              "      <td>0.998365</td>\n",
              "      <td>Roses are Red (Alex Cross, #6)</td>\n",
              "      <td>2001.0</td>\n",
              "      <td>Mystery</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>581274</td>\n",
              "      <td>0.994040</td>\n",
              "      <td>London Bridges (Alex Cross, #10)</td>\n",
              "      <td>2004.0</td>\n",
              "      <td>Mystery</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>79379</td>\n",
              "      <td>0.992481</td>\n",
              "      <td>Violets Are Blue (Alex Cross, #7)</td>\n",
              "      <td>2002.0</td>\n",
              "      <td>Mystery</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>772163</td>\n",
              "      <td>0.977474</td>\n",
              "      <td>Notorious: The Life of Ingrid Bergman</td>\n",
              "      <td>1997.0</td>\n",
              "      <td>History/Biography</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>247921</td>\n",
              "      <td>0.976010</td>\n",
              "      <td>Katharine Hepburn</td>\n",
              "      <td>1996.0</td>\n",
              "      <td>History/Biography</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>847106</td>\n",
              "      <td>0.975287</td>\n",
              "      <td>The Million Dollar Mermaid</td>\n",
              "      <td>1999.0</td>\n",
              "      <td>History/Biography</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>474514</td>\n",
              "      <td>0.974411</td>\n",
              "      <td>Howard Hughes: The Secret Life</td>\n",
              "      <td>2004.0</td>\n",
              "      <td>History/Biography</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>782385</td>\n",
              "      <td>0.973951</td>\n",
              "      <td>Ginger: My Story</td>\n",
              "      <td>1991.0</td>\n",
              "      <td>History/Biography</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>33014</td>\n",
              "      <td>0.973891</td>\n",
              "      <td>Thomas Hardy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>History/Biography</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   book_id     score  ... publication_year              genre\n",
              "0    21436  0.999662  ...           2007.0            Mystery\n",
              "1    79378  0.998365  ...           2001.0            Mystery\n",
              "2   581274  0.994040  ...           2004.0            Mystery\n",
              "3    79379  0.992481  ...           2002.0            Mystery\n",
              "4   772163  0.977474  ...           1997.0  History/Biography\n",
              "5   247921  0.976010  ...           1996.0  History/Biography\n",
              "6   847106  0.975287  ...           1999.0  History/Biography\n",
              "7   474514  0.974411  ...           2004.0  History/Biography\n",
              "8   782385  0.973951  ...           1991.0  History/Biography\n",
              "9    33014  0.973891  ...              NaN  History/Biography\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "content_recom_df = getContentRecoms(16)\n",
        "\n",
        "print(\"Books recommended to user based on previously read and reviewed books:\")\n",
        "content_recom_df.toPandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, the top 4 recommendations are books in the Alex Cross series which are clearly base on the inputted book Jack & Jill (Alex Cross, #3). The model seems to quite heavily favour books from the same series, this is unsurprising as we are performing TF-IDF on the titles. This is not necessarily a bad thing, if a user read a book from a series and rated it above a 3, then they probably are likely to be interested in other books in that series also. The remainder of the recommender books are biographies, which seem to be inline with the reader's interests."
      ],
      "metadata": {
        "id": "1QriM5p-IMw-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 2**"
      ],
      "metadata": {
        "id": "9Jjoc3AJBSp2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 672
        },
        "id": "xuS4aXjrMHuW",
        "outputId": "cfe1d26a-5445-4fbf-f92a-5ca82a8b4545"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Books previously read and reviewed by user:\n",
            "+-------+------------------------------------------------------------------------------------+----------------+-----------------+\n",
            "|book_id|title                                                                               |publication_year|genre            |\n",
            "+-------+------------------------------------------------------------------------------------+----------------+-----------------+\n",
            "|14653  |Encyclopedia Brown and the Case of the Disgusting Sneakers (Encyclopedia Brown, #18)|null            |Children         |\n",
            "|14652  |Encyclopedia Brown: Boy Detective (Books 1-4)                                       |2002.0          |Children         |\n",
            "|14656  |Encyclopedia Brown Solves Them All (Encyclopedia Brown, #5)                         |1992.0          |Children         |\n",
            "|1067   |1776                                                                                |null            |History/Biography|\n",
            "|14653  |Encyclopedia Brown and the Case of the Disgusting Sneakers (Encyclopedia Brown, #18)|null            |Mystery          |\n",
            "|14652  |Encyclopedia Brown: Boy Detective (Books 1-4)                                       |2002.0          |Mystery          |\n",
            "|14656  |Encyclopedia Brown Solves Them All (Encyclopedia Brown, #5)                         |1992.0          |Mystery          |\n",
            "|14703  |Faust I & II                                                                        |1994.0          |Poetry           |\n",
            "+-------+------------------------------------------------------------------------------------+----------------+-----------------+\n",
            "\n",
            "Books recommended to user based on previously read and reviewed books:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>book_id</th>\n",
              "      <th>score</th>\n",
              "      <th>title</th>\n",
              "      <th>publication_year</th>\n",
              "      <th>genre</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>77347</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1776</td>\n",
              "      <td>2005.0</td>\n",
              "      <td>History/Biography</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>864286</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>Faust</td>\n",
              "      <td>1999.0</td>\n",
              "      <td>Poetry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14704</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>Faust</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>Poetry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>406373</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>Faust</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Poetry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>789345</td>\n",
              "      <td>0.993900</td>\n",
              "      <td>Encyclopedia Brown and the Case of the Midnigh...</td>\n",
              "      <td>1982.0</td>\n",
              "      <td>Children</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>871145</td>\n",
              "      <td>0.993244</td>\n",
              "      <td>Encyclopedia Brown Saves the Day</td>\n",
              "      <td>1982.0</td>\n",
              "      <td>Children</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>14655</td>\n",
              "      <td>0.991380</td>\n",
              "      <td>Encyclopedia Brown Finds the Clues (Encycloped...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Children</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>14655</td>\n",
              "      <td>0.991380</td>\n",
              "      <td>Encyclopedia Brown Finds the Clues (Encycloped...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Mystery</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>871145</td>\n",
              "      <td>0.988393</td>\n",
              "      <td>Encyclopedia Brown Saves the Day</td>\n",
              "      <td>1982.0</td>\n",
              "      <td>Children</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>24159</td>\n",
              "      <td>0.988210</td>\n",
              "      <td>Encyclopedia Brown Takes the Cake! (Encycloped...</td>\n",
              "      <td>1991.0</td>\n",
              "      <td>Children</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>197169</td>\n",
              "      <td>0.984606</td>\n",
              "      <td>Only Yesterday: An Informal History of the 1920's</td>\n",
              "      <td>2010.0</td>\n",
              "      <td>History/Biography</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    book_id     score  ... publication_year              genre\n",
              "0     77347  1.000000  ...           2005.0  History/Biography\n",
              "1    864286  1.000000  ...           1999.0             Poetry\n",
              "2     14704  1.000000  ...           2000.0             Poetry\n",
              "3    406373  1.000000  ...              NaN             Poetry\n",
              "4    789345  0.993900  ...           1982.0           Children\n",
              "5    871145  0.993244  ...           1982.0           Children\n",
              "6     14655  0.991380  ...              NaN           Children\n",
              "7     14655  0.991380  ...              NaN            Mystery\n",
              "8    871145  0.988393  ...           1982.0           Children\n",
              "9     24159  0.988210  ...           1991.0           Children\n",
              "10   197169  0.984606  ...           2010.0  History/Biography\n",
              "\n",
              "[11 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "content_recom_df = getContentRecoms(22)\n",
        "\n",
        "print(\"Books recommended to user based on previously read and reviewed books:\")\n",
        "content_recom_df.toPandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example we can see one of the limitations of the dataset. The same book can be published by multipler publishers and in different formats. For this reason we are seeing one book appear in both the recommender list as in the read list, as well as one book being repeated 3 times. However, if we look beyond that the rest of the suggestions seem highly relevant. The system has identified Encyclopedia Brown books as similar to each other and has picked up on this person's interest in history. The system appears to be perfoming as intended."
      ],
      "metadata": {
        "id": "A5nnUjOEJ14o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "P4mHEnM-j9IH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To evaluate our model we will use mean average precision (MAP). In order to make recommendations for a user we need at least one interaction present in the training set. To ensure that each user's interactions are split between the training and test set we will apply a stratified split by declaring the fraction for each user as 0.75. Accordingly, 75% each user's interactions will be in the training set and 25% in the test set."
      ],
      "metadata": {
        "id": "4OT40wfaEjJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fractions = interactions_df.select(\"user_id\").distinct().withColumn(\"fraction\", lit(0.75)).rdd.collectAsMap()\n",
        "train = interactions_df.sampleBy(\"user_id\", fractions, seed=10)\n",
        "\n",
        "# Subtracting 'train' from original df to get test set \n",
        "test = interactions_df.subtract(train)"
      ],
      "metadata": {
        "id": "q4Pt1OvDquyw"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get unique values in the grouping column\n",
        "groups = [x[0] for x in test.select(\"user_id\").distinct().collect()]\n",
        "\n",
        "# Create a filtered DataFrame for each group in a list comprehension\n",
        "groups_list = [test.filter(col('user_id')==x) for x in groups]"
      ],
      "metadata": {
        "id": "FGIZXi0ptuu-"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision = []\n",
        "# for time purposes, we will only the precision compute 50 samples\n",
        "for group in groups[0:50]:\n",
        "  user = group\n",
        "  recs = getContentRecoms(user,display=False).select('book_id').collect()\n",
        "  acc = test.filter(col('user_id')==user).select('book_id').collect()\n",
        "  prec = len(set(acc).intersection(set(recs)))/len(acc)\n",
        "  precision.append(prec)"
      ],
      "metadata": {
        "id": "Op4lCPinuS3b"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('MAP: ' + str(np.mean(precision)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Btt_NDzHBDEc",
        "outputId": "ab1c0e25-ad94-4ada-88d5-79d36c9fa56d"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAP: 0.019385964912280697\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "content_based.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMWnrPJWg7Ehu0ivePICi16"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}